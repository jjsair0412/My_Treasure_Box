# kafka 실사례 아키텍처
## 아키텍쳐 측의 카프카 사용방안
카프카를 사용하는 application은 , 절대 Kafka cluster와 직접 접근하는것은 운영상에 문제점이 있을 수 있습니다.

### **프록시 producer나 consumer application을 구성해서 , 프록시를 통해 접근하면 아래와 같은 이점이 있습니다.**
>- **보안:**
>
>프록시를 사용하면, 외부 애플리케이션에서 Kafka 클러스터까지의 연결을 제한하고, 특정 프로토콜과 인증 메커니즘을 강제할 수 있습니다. 이로 인해 보안 위반의 가능성을 줄일 수 있습니다.
>
>- **접근 제어:**
>
>프록시를 거치게 되면, 특정 사용자나 애플리케이션의 접근을 제한하거나, 특정 토픽에 대한 접근만 허용하는 등의 세세한 접근 제어가 가능해집니다.
>
>- **로드 밸런싱:**
>
>프록시는 다수의 클라이언트 요청을 균등하게 Kafka 클러스터의 노드들에 분배하는 역할을 합니다. 이로 인해 Kafka 클러스터에 대한 부하를 균등하게 분산시킬 수 있습니다.
>
>- **모니터링 및 로깅:**
>
>프록시를 통과하는 모든 트래픽을 모니터링하고 로깅함으로써, 문제 발생 시 디버깅을 용이하게 할 수 있습니다.
>
>- **프로토콜 변환:**
>
>특정 환경에서는 클라이언트와 Kafka 클러스터 간의 프로토콜이 일치하지 않을 수 있습니다. 프록시를 사용하면, 이러한 프로토콜 불일치 문제를 해결하고 중간에서 데이터를 변환해주는 역할을 합니다.
>
>- **멀티 테넌시:**
>
>여러 테넌트가 동일한 Kafka 클러스터를 사용하는 경우, 프록시를 통해 각 테넌트의 트래픽을 분리하거나, 리소스를 격리하는 등의 역할을 수행할 수 있습니다.

## 파티션 개수 및 replication factor 개수 정하기
Kafka를 클러스터를 구성할 때 , 가장 먼저 고려해야하고 가장 중요한 요소는 , 다음 두 가지입니다.

**1. 파티션 개수**

**2. replication 개수**

이 둘은 , 시스템의 성능과 데이터 지속성에 영향을 미치기 때문에 , 처음 설계할 때 잘 설계해야만 합니다
>만약 파티션 두개 , replication factor 가 2인 토픽이 있다 생각했을 경우
> 
> 토픽 생성 후 데이터를 받아오는 와중 (라이프사이클 도중) 파티션 개수를 늘린다면 , **키 순서를 보장할 수 없게 됩니다.**
> 
> 또한 replication factor 개수를 늘린다면 , 네트워크 통신이 증가하며 , 디스크 공간또한 많아지기 때문 시스템 부하가 커집니다.

### 파티션 개수를 어떻게 정해야 할까 ?
파티션이 많아지면 많아질수록 병렬 작업이 많아지며 , 컨슈머 그룹 내에서 활성화 시킬 수 있는 컨슈머의 최대치는 , 토픽의 파티션 개수기 때문에 파티션 수가 많아지면
컨슈머의 수도 많아집니다.

따라서 파티션과 replication factor 개수를 정할 때 , 아래 근거에 따라서 생각해보면 쉽습니다.

***1. 브로커 개수가 6개 미만***
- 브로커 개수에 3을 곱함

***2. 브로커 개수가 12개를 초과하는 큰 클러스터라면***
- 브로커 개수에 2를 곱함

>이 숫자를 늘려야하는 상황은 , 그룹 안에 컨슈머가 많고 최대 스루풋 상황에서 컨슈머를 병렬 처리해야 할 때에 늘려야 합니다.
>
> 또한 프로듀서측 스루풋이 높거나 , 높아질 예상이라면 처음부터 파티션 개수를 많이 두는것이 좋습니다.
> 
> 늘려두고 , 계속 테스트해보면서 가장 적절한 개수를 찾아야만 합니다.

### replication factor 개수를 어떻게 정해야 할까?
운영 환경에선 최소 2개
- 보통은 3개, 최대치 4개
- 처음엔 3개부터 시작. **절대 1개는 안됨**

replication factor가 높을수록 시스템 지속성에 이점이 많음.

***acks=all*** 일 경우 레이턴시가 길어짐.
- 모든 replication factor에게 acks를 받아야하기 때문.

#### recommend option
클러스터 안의 파티션 최대 개수는 20만개

**브로커별 파티션 4천개가 권장됨**
- 주키퍼의 소프트웨어적 한계 : 따라서 주키퍼 없이 작동하는 craft 모드가 나왔음
    - ex) 클러스터에 파티션 20만개가 있을 경우 , 브로커는 50개라는 의미

>처음엔 적당한 개수로 시작하고 , 테스트를통해 점차 늘려나가야 함.

## kafka topic 이름짓기
- [kafka topic 이름짓기 가이드라인 블로그](https://cnr.sh/essays/how-paint-bike-shed-kafka-topic-naming-conventions)

위 블로그에 나온 것 처럼, 아래 양식을 따르면 좋음
- 또한 snake 표기법을 따르는게 좋음
```bash
<message type>.<dataset name>.<data name>


# ex) message type : logging , tracking , streaming , push , user
# dataset name : RDBMS 이름 짓는방법과 비슷함. 토픽을 묶기 위한 카테고리
# data name
```

## kafka bigData 사용 방안
Kafka가 만들어진 근본적인 이유는 , **빅데이터를 적재하기 위해**서 입니다.

카프카는 Application의 모든 타입의 데이터들을 다 가지고 와서 , 데이터를 실시간 처리하거나 BATCH로 다른 빅데이터 저장공간에 데이터를 적제합니다.

둘 작업은 병렬로 수행됩니다.

- 실시간 처리
> Spark, storm, Flink 등의
빅데이터 프레임워크를 통해 실시간으로 분석하거나 대시보드를 구성하는 등의 작업을 수행합니다.

- BATCH 처리
>Kafka Connect를 통해 Kafka에 적재된 데이터를 Hadoop , S3, RDBMS로 적재한 다음 데이터 사이언티스트나 백업 등의 작업을 수행합니다.

 
## kafka logging & Metrics 사용 방안
- 꼭 알고있어야하는 아키텍처

### 순서
1. Kafka에 아래와 같은 두가지 토픽을 생성

   - 1. application_logs
   - 2. application_metrics

2. 모든 Application에서 발생하는 로그와 metric값을 각 토픽에 전송

3. Kafka Connect Slink를 통해 Kafka에 적재된 로그와 메트릭값을 ELK, Splunk, CloudWatch 등 로깅 솔루션으로 전달