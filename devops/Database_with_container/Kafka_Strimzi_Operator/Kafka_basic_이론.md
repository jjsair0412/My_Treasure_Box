# Kafka란 ?
미국 linkedin에서 개발했으며, pub-sub 모델의 메시지 큐 종류 입니다.
## 1. Kafka를 왜 쓸까 ?
Kafka docs에서는 이벤트 스트리밍을 위해 Kafka를 사용한다고 합니다.

이때 이벤트 스트리밍은 , 수많은 소프트웨어들이 실시간으로 상시 작동하기 위한 기술을 의미합니다.

예를들어 DB , IOT 센서 , 클라우드 서비스 APP에서 발생하는 이벤트를 나중에 검색할 수 있도록 지속적으로 저장하거나 다른 대상 기술로 전달하여 적제적소에 올바른 위치에 있도록 도와주는것이 이벤트 스트리밍 입니다.

따라서 , **Kafka는 여러 APP에서 발생한 이벤트를 효과적으로 처리하기 위해 사용** 하며 , **이벤트 스트리밍 플랫폼** 이라 할 수 있습니다.

- Kafka는 수많은 어플리케이션이나 서비스에서 발생하는 이벤트 (메시지) 를 
실시간으로 처리하고 모니터링하기 위해서 사용합니다.

## 2. Kafka의 주요 기능
Kafka의 주요 기능은 세 분류로 나눌 수 있습니다.
1. 다른 시스템에서 데이터를 지속적으로 import/export 작업을 포함하여 이벤트 스트림을 게시 (write)하고 구독 (read) 합니다 .
    - 실시간 처리 가능
2. 원하는 기간 동안 지속적이고 안정적으로 이벤트 스트림을 저장합니다 .
    - 이벤트 (메시지) 저장 가능
3. 발생 시 또는 소급하여 이벤트 스트림을 처리합니다 .

또한 TCP 프로토콜로 작동하기에 서버와 클라이언트 구조로 구성되어 있으며 , 베어메탈이나 클라우드 서비스 , k8s 위에 올라가서 작동할 수 있도록 분산되어 개발됐기에 확장성이 뛰어납니다.

## 3. Kafka 구성 요소
### 3.1 Zookeeper
- Kafka의 메타데이터(metadata) 관리 및 브로커의 정상상태 점검(health check) 을 담당 합니다. 

### 3.2 Kafka || Kafka cluster
- 여러 대의 브로커를 구성한 클러스터를 의미 합니다.

### 3.3 broker
- 카프카 애플리케이션이 설치된 서버 또는 노드를 의미 합니다.
- 각 브로커들은 int 형식의 ID로 구분됩니다.
    - ex ) Broker 101 , Broker 102 , Broker 103 ...


각 브로커는 고유의 토픽 파티션을 갖고 있으며 , 프로듀서가 브로커에게 데이터를 전달하면 , 모든 브로커에게 분산되어 저장됩니다.

**Kafka Broker는 Bootstrap broker 메커니즘이 있어서 , client및 프로듀서 , 컨슈머가 Kafka cluster의 아무 broker에게만 연결해도 모든 broker에게 자동으로 연결됩니다.**
- 이말은 broker가 수평 확장될 수 있다는 의미. 3개에서 4개로 늘어나도 client , 프로듀서 , 컨슈머가 모든 broker를 알 필요가 없다는 의미..
- Kafka의 Broker들은 Kafka cluster에 존재하는 모든 Broker의 metadata를 공유하기에, 이게 가능함.
- 기본적으로 3개의 Broker 구성이 기본 아키텍처라고들 함

#### 3.3.1 Broker with Topic
생성할 토픽 파티션 개수가 Broker 개수보다 모자라더라도 , 파티션은 모든 Broker에게 분산되어 저장됩니다.

많더라도 분산되어 저장됩니다.

### 3.4 event || message || record
- 카프카는 APP에서 어떤 일이 일어낫다 라는 사실을 기록하고 , 해당 데이터를 Kafka에서 데이터 형식으로 읽거나 씁니다.
- 프로듀서가 브로커로 전송하거나 컨슈머가 브로커로부터 읽어가는 데이터 조각을 말합니다.

### 3.5 Producers
- 프로듀서는 events를 생성하여 Kafka로 전달하는 클라이언트 계층 APP 입니다.

### 3.6 consumer
- Kafka에서 events를 읽고 처리하는 APP 입니다.

### 3.7 Topic
- Kafka는 events를 토픽별로 저장하고 영구적(설정에 따라 다름) 으로 저장됩니다.
-Topic은 큐 (선입선출) 구조를 갖고 있으며 , 토픽의 이벤트는 필요한 만큼 자주 읽을 수 있습니다. 
- 기존 메시징 시스템과 달리 이벤트는 소비 후 삭제되지 않습니다. 대신 **Kafka가 주제별 구성 설정을 통해 이벤트를 유지해야 하는 기간을 정의**합니다. 그 후에는 이전 이벤트가 삭제됩니다. 
- Kafka의 성능은 데이터 크기와 관련하여 실질적으로 일정하므로 장기간 데이터를 저장해도 괜찮습니다.

Topic은 데이터 포멧을 다 지원합니다.
- json , Avro , txt 다 보내도 상관없음.

Topic안에 있는 메세지들의 순서를 **데이터 스트림**이라고 함

### 3.8 partition
- topic은 여러 버킷에 분산되어 저장됩니다.

- 분산저장은 client app이 여러 브로커에서 병렬 처리가 가능하게끔 하여 속도 향상과 확장성에 도움을 주는데, 이러한 **events를 topic에 분산 저장 할 수 있게끔 Topic을 여러개로 나눈것**을 의미합니다.

![partition](../Images/partition.PNG)

- 사진에서 P1, P2, P3, P4가 파티션들입니다.

파티션 안의 메시지는 id값을 가지고 , 0부터 1씩 오르는데 이 값을 **오프셋**이라 합니다.


#### 3.8.1 Topic replication factor 의 방법
**replication된 파티션은 ISR(In-sync replica)** 이라 함

각 파티션은 replica를 갖기에 리더가 있어야 하며 , **오직 1개의 브로커만 특정 파티션의 리더가 될 수 있습니다..**

**프로듀서는 리더 파티션에게만 데이터를 보낼 수 있음.. 똑같이 컨슈머도 리더 파티션에서만 데이터를 받을 수 있음..**
- 이말은 프로듀서와 컨슈머가 어떤 브로커의 파티션에게 데이터를 보내고 받는지를 알고 있다는 의미 합니다.

만약 리더가 죽으면 ISR이 리더가 됩니다.

    ISR의 반대 , OSR

    OSR은 "Out-of-Sync Replicas"의 약자로, ISR 목록에 현재 포함되지 않는 복제본을 나타냅니다. 
    이러한 복제본은 리더와 충분히 동기화되지 않았기 때문에, 현재의 데이터 상태를 정확하게 반영하지 않을 수 있습니다.

    만약 복제본이 일정 시간 동안 리더와 동기화되지 않으면 (예: 네트워크 문제, 디스크 문제 등으로 인해), 해당 복제본은 ISR에서 제거되고 OSR 목록에 추가됩니다. 일단 문제가 해결되고 해당 복제본이 리더와 다시 동기화되면, 다시 ISR 목록에 추가됩니다.

    따라서, ISR은 현재 데이터 상태를 안전하게 유지하고 있는 복제본을, OSR은 그렇지 않은 복제본을 나타냅니다. Kafka 클러스터의 건강 상태를 모니터링할 때, OSR에 있는 복제본의 수를 주시하는 것이 중요합니다. OSR에 복제본이 지속적으로 존재한다면, 클러스터에 문제가 있을 수 있음을 나타냅니다.

## 4. Kafka 주요 특징
- 높은 처리량
    - 묶음 단위 배치처리로 대용량의 실시간 로그 등 데이터를 처리하는것에 적합합니다.
- 확장성
    - Kafka cluster의 브로커를 스케일 인 하거나 스케일 아웃하면서 확장성의 이점이 있습니다.
- 영속성
    - 다른 메세징 플랫폼과 다르게, 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장합니다.
- 고 가용성
    - 서버/브로커 장애 시 데이터 복제로 지속적인 데이터 처리가 가능합니다.

## 5. Producer 주요 특징
Kafka Topic에 메세지를 보내는 주체를 Producer 라 합니다..

프로듀서는 LB를 통해서 특정 토픽 안에 파티션들에게 특정 알고리즘방식을 통해 메시지를 보내게 되기 때문에 , Kafka는 스케일링 합니다.

### 5.1 Producers : Message keys
프로듀서는 메시지에 키를 추가해서 토픽안의 여러 파티션에 값을 넣을 때 사용하게 됩니다.

key값이 null이라면 , 데이터는 라운드로빈 방식으로 메시지를 보냅니다.

Key값이 null이 아니라면 , 프로듀서는 항상 같은 파티션에 메시지를 보내기 때문에 , 특정 필드에 대한 메시지 순서 설정을 해야 합니다.

### 5.2 Kafka Message Serializer
Kafka 메세지를 생성시키는 주체.

메시지를 보낼 때 , 프로듀서에서 평상시 객체를 byte 데이터 직렬화가 필요합니다.
- 실제 123 , helloworld같은 문자나 숫자를 0101 인 2진 데이터로 직렬화하고 보내야 함.

ex )
- **KeySerializer=IntegerSerializer**로 int값을 byte로 변환하여 브로커로 전달
- **ValueSerializer=StringSerializer**로 String값을 byte로 변환하여 브로커로 전달

**Kafka는 이런 Message Serializer를 통해 byte 데이터 직렬화를 해서 Kafka에 보내기 때문에 , 어떤 데이터 포멧을 가진 값이 오더라도 토픽에 보낼 수 있는것 입니다.**


### **5.3 Producer Acknowledgements (acks)**
프로듀서는 브로커에게 데이터가 정상적으로 보내졌는지를 acks 로 확인할 수 있습니다.

- ***1. acks = 0 :*** 
    - 프로듀서가 데이터 송신 확인을 기다리지 않음. 
    - 프로듀서가 메세지를 보낸 순간 메시지쓰기에 성공했다고 간주함 , 브로커가 down되었거나 에러가 발생해도 , 알 수 없으며 그때 날아간 데이터는 손실됨.
        - 브로커가 다운됬을 경우 데이터 유실 가능성 있음.
        - 메세지를 유실되도 괜찮을때 유용함.
        - 해당 설정의 네트워크 오버헤드가 최소화되면서 속도가 빠르고 처리량이 제일 클때 사용함
- ***2. acks = 1 :*** 
    - 프로듀서가 리더 파티션에게만 송신 확인을 받음. 
    - 리더 브로커에게 메세지 전송이 완료되었다는 응답을 받을 때 메시지쓰기에 성공했다고 간주함.
    - 리더 파티션에게 전송은 됬는데 , 그 데이터가 isr에 복제가 정상적으로 되었는지는 모름.
        - 리더 파티션을 갖고 있는 브로커가 다운됬을 경우 데이터 유실 가능성 있음.
        - 요청 헤드에따라 네트워크 오버헤드가 커지지만 , 조금더 안정적임.
- ***3. acks = all , -1 :*** 
    - 리더 및 ISR 파티션에게 모두 송신 확인을 받음. 
    - ISR 파티션에서 메시지를 수신했을 때 메시지가 정상적으로 쓰여졋다고 간주함.
        - 3.0 이상 버전의 기본 옵션
        - 데이터 유실 가능성 없음
- ***3.1 min.insync.replicas***
    - 확인응답을 몇개의 ISR 이 보낼것인가에대한 설정.
    - ack = all 옵션에서 , 리더 레플리카가 , 현재 클러스터 내의 동기화된 레플리카 개수만으로 안전한 쓰기가 가능한지 확인하는 옵션 . 이것을 min.insync.replicas 옵션으로 제어함.
    - 해당 설정값에 살아있어야만 하는 브로커 개수가 정해짐.
        - min.insync.replicas=1 :
            - 기본 옵션. 리더 브로커만 성공적으로 확인 응답을 보내면 됨.
        - min.insync.replicas=2 :
            - 리더 브로커와 적어도 1개 이상의 ISR 이 확인 응답을 보내야 함


## 6. Consumer 주요 특징
Kafka 토픽 파티션 안에있는 데이터를 읽어오는 주체

컨슈머는 Kafka 토픽 파티션에 있는 데이터를 Pull 모델을 통해 받아오고 , 파티션에 있는 데이터를 받아오는 순서는 low to high로 받아 옵니다
- ex ) offset 0부터 1 , 2 , 3 ,, 순서대로 받아옴

특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지 브로커 내부에서 사용되는 내부 토픽 ```__consumer_offsets``` 에 기록됩니다.

브로커가 fail 상태라면 , 컨슈머는 재해 복구를 어떻게 할지 미리 정합니다.

### 6.2 Consumer Deserializer
카프카에서 받은 데이터를 바이트 객체로 변환하는 역할을 합니다.
- Programming 언어로 처리할 수 있는 객체로 변환시킵니다.

ex ) 
- **KeyDeserializer=IntegerDeserializer**로 브로커에서 byte로 들어온 데이터를 int로 변환
- **ValueDeserializer=StringDeserializer**로 브로커에서 byte로 들어온 데이터를 String으로 변환

## 7. Topic replication factor - Kafka Topic의 재해복구 방법
Kafka Topic은 replication factor라는것을 가집니다.

만약 각 토픽 설정이 아래와 같이 동일하다고 볼 때
- Topic 2개 
- 파티션 1개
- replication factor 1개
- Broker 3대

각 토픽과 파티션은 각 Broker에게 분산 저장되는데, **replication factor가 1개**로 설정되어 있기 때문에 **다른 Broker (내가 가진 파티션을 다른 브로커에게 복재시켜둠) 에게 파티션 1개를 복재 시킵니다.**
- **이것은 특정 브로커가 죽어도, 데이터를 잃지 않고 계속 제공할수 있도록 한다.**
